https://diveintopython3.problemsolving.io/table-of-contents.html
https://www.khanacademy.org/computing/computer-science/algorithms/recursive-algorithms/pc/challenge-iterative-factorial
https://spoken-tutorial.org/tutorial-search/?search_foss=Python%203.4.3&search_language=English&page=1
https://towardsdatascience.com/best-practices-for-caching-in-spark-sql-b22fb0f02d34
https://spark.apache.org/docs/latest/rdd-programming-guide.html#:~:text=By%20default%2C%20each%20transformed%20RDD,next%20time%20you%20query%20it.
https://www.oreilly.com/library/view/data-analytics-with/9781491913734/ch04.html
https://www.1keydata.com/datawarehousing/datawarehouse.html
https://www.nuwavesolutions.com/snapshot-fact-tables/
http://www.kimballgroup.com/wp-content/uploads/2013/08/2013.09-Kimball-Dimensional-Modeling-Techniques11.pdf
http://dbis.cs.tu-dortmund.de/cms/de/lehre/ws1415/dw/slides/modelling.pdf
https://medium.com/programminghero/learning-python-in-1-month-resources-beginner-study-plan-655fba3b5249
https://www.quora.com/What-is-an-ideal-checklist-to-learn-Python-in-30-days
https://www.khanacademy.org/computing/computer-science/algorithms/binary-search/a/binary-search
https://www.khanacademy.org/computing/computer-science
https://onlinedegree.iitm.ac.in/


pyspark  --driver-memory 10G --executor-memory 10G --executor-cores 5 --num-executors 10  --jars  jarpath/

CSV LOAD VIA SPARK
======================

read_file = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").load("/user/gishrqa/events/DW_-_Hadoop_Employee_Data_-_For_Missing_Employees.csv").saveAsTable("hr_lz.missing_hc")

read_file = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").schema(customSchema).option("delimiter", ",").option('mode','PERMISSIVE').option("parserLib", "UNIVOCITY").load("/user/gishrqa/events/test_csv.csv").alias("read_file")


Spark Settings
================
set spark.sql.hive.convertMetastoreParquet=false
sqlContext.conf.set("spark.sql.hive.convertMetastoreParquet","false") 

sqlContext.conf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")
sqlContext.conf.set('spark.kryoserializer.buffer.mb', '1000')
sqlContext.conf.set('spark.kryoserializer.buffer.max', '1g') 


HIVE CONFIGURATIONS======================

SET hive.exec.dynamic.partition=true;
SET hive.exec.dynamic.partition.mode = nonstrict;
SET hive.vectorized.execution.enabled=true;
SET hive.exec.parallel=true;
set mapreduce.map.memory.mb=8192;
set mapreduce.reduce.memory.mb=8192;
set mapreduce.map.java.opts=-Xmx3276m;
set mapreduce.reduce.java.opts=-Xmx3276m;

set mapreduce.reduce.memory.mb=9000;
set mapreduce.reduce.java.opts=-Xmx5276m;
set mapreduce.map.java.opts=-Xmx5276m;
set mapreduce.map.java.opts.max.heap=9000;
set mapreduce.reduce.java.opts.max.heap=20240;
set hive.optimize.sort.dynamic.partition=true; 
SET mapred.child.java.opts=-Xmx4G -XX:+UseConcMarkSweepGC -XX:-UseGCOverheadLimit;

https://0x0fff.com/ 
https://developers.google.com/machine-learning/crash-course/ml-intro 
https://github.com/vaquarkhan/problems-and-solutions/tree/master/bin/hackerrank1
https://github.com/JerryLead/SparkInternals/blob/master/markdown/english/6-CacheAndCheckpoint.md 
https://medium.com/polar-tropics/improving-spark-job-performance-while-writing-parquet-by-300-40ccf487a6a5 
https://journalofcloudcomputing.springeropen.com/articles/10.1186/s13677-014-0012-6 
https://www.hackerearth.com/practice/algorithms/sorting/bubble-sort/practice-problems/algorithm/twisted-matrix/
